# ДЗ по "Сбор и разметка данных (семинары)"

## Семинар 6. Scrapy. Парсинг фото и файлов
* Домашнее задание: 
1.	Создайте новый проект Scrapy. Дайте ему подходящее имя и убедитесь, что ваше окружение правильно настроено для 
работы с проектом.
2.	Создайте нового паука, способного перемещаться по сайту www.unsplash.com. Ваш паук должен уметь перемещаться 
по категориям фотографий и получать доступ к страницам отдельных фотографий.
3.	Определите элемент (Item) в Scrapy, который будет представлять изображение. Ваш элемент должен включать такие 
детали, как URL изображения, название изображения и категорию, к которой оно принадлежит.
4.	Используйте Scrapy ImagesPipeline для загрузки изображений. Обязательно установите параметр IMAGES_STORE в файле 
settings.py. Убедитесь, что ваш паук правильно выдает элементы изображений, которые может обработать ImagesPipeline.
5.	Сохраните дополнительные сведения об изображениях (название, категория) в CSV-файле. Каждая строка должна 
соответствовать одному изображению и содержать URL изображения, локальный путь к файлу (после загрузки), 
название и категорию.

---
# Решение

Устанавливаем пакет scrapy
```commandline
pip install scrapy
```
Для скачивания картинок нужно установить модуль pillow
```commandline
pip install pillow
```

Устанавливаем клиента БД MongoDB
```commandline
pip install pymongo
```

Запускаем паука из консоли
```commandline
scrapy crawl unsplashcom
```

---

# Памятка, чтоб не забыть
Создаем проект 'imgparser' в текущим каталоге (точка означает тек. каталог)
```commandline
scrapy startproject imgparser .
```

Создаем паука 'unsplashcom' который будет работать на домене unsplash.com
```commandline
scrapy genspider unsplashcom unsplash.com
```

Запускаем паука из консоли
```commandline
scrapy crawl unsplashcom
```

