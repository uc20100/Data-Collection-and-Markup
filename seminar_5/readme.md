# ДЗ по "Сбор и разметка данных (семинары)"

## Семинар 5. Scrapy
* Домашнее задание:  
1.	Найдите сайт, содержащий интересующий вас список или каталог. Это может быть список книг, фильмов, спортивных команд или что-то еще, что вас заинтересовало.
2.	Создайте новый проект Scrapy и определите нового паука. С помощью атрибута start_urls укажите URL выбранной вами веб-страницы.
3.	Определите метод парсинга для извлечения интересующих вас данных. Используйте селекторы XPath или CSS для навигации по HTML и извлечения данных. Возможно, потребуется извлечь данные с нескольких страниц или перейти по ссылкам на другие страницы.
4.	Сохраните извлеченные данные в структурированном формате. Вы можете использовать оператор yield для возврата данных из паука, которые Scrapy может записать в файл в выбранном вами формате (например, JSON или CSV).
5.	Конечным результатом работы должен быть код Scrapy Spider, а также пример выходных данных. Не забывайте соблюдать правила robots.txt и условия обслуживания веб-сайта, а также ответственно подходите к использованию веб-скрейпинга.

---
# Решение:
Паук настроен на сканирование сайта https://www.labirint.ru/ в разделе 'Фантастика'  
Запускаем паука из консоли:
```commandline
scrapy crawl labirintru
```
Результаты работы паука в файлах JSON и CSV.